import numpy as np
import scipy.io
from scipy.signal import welch
from scipy.stats import entropy
from scipy.special import erf
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

print("=" * 60)
print("CWRUè½´æ‰¿æ•…éšœè¯Šæ–­ - ä¼˜åŒ–ç‰ˆæœ¬")
print("=" * 60)

# ============================================================================
# ä¼˜åŒ–çš„IMSDEç‰¹å¾æå–
# ============================================================================

def optimized_multiscale_dispersion_entropy(signal, m, tau, c):
    """ä¼˜åŒ–çš„å¤šå°ºåº¦æ•£å¸ƒç†µè®¡ç®— - é¿å…è®¡ç®—çˆ†ç‚¸"""
    # å‚æ•°å®‰å…¨æ£€æŸ¥
    if m > 6:  # é™åˆ¶mçš„æœ€å¤§å€¼
        m = 6
        print(f"è­¦å‘Š: må‚æ•°è‡ªåŠ¨é™åˆ¶ä¸º6ä»¥é¿å…è®¡ç®—çˆ†ç‚¸")
    
    if c > 8:  # é™åˆ¶cçš„æœ€å¤§å€¼
        c = 8
        print(f"è­¦å‘Š: cå‚æ•°è‡ªåŠ¨é™åˆ¶ä¸º8ä»¥é¿å…è®¡ç®—çˆ†ç‚¸")
    
    # ç¬¦å·åŒ–å¤„ç†
    sigma = np.std(signal)
    mu = np.mean(signal)
    
    # ä½¿ç”¨æ­£æ€åˆ†å¸ƒCDFè¿›è¡Œç¬¦å·åŒ–
    y = (signal - mu) / (sigma + 1e-8)
    cdf_values = 0.5 * (1 + erf(y / np.sqrt(2)))
    
    # æ˜ å°„åˆ°æ•´æ•°ç¬¦å·
    z = np.floor(c * cdf_values + 1).astype(int)
    z = np.clip(z, 1, c)
    
    # æ„å»ºæ¨¡å¼ - ä½¿ç”¨å­—å…¸é¿å…å¤§æ•°ç»„
    pattern_dict = {}
    n = len(z) - (m - 1) * tau
    
    for i in range(n):
        pattern = 0
        for j in range(m):
            pattern += (z[i + j * tau] - 1) * (c ** (m - 1 - j))
        
        if pattern in pattern_dict:
            pattern_dict[pattern] += 1
        else:
            pattern_dict[pattern] = 1
    
    # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ
    total = sum(pattern_dict.values())
    prob = np.array(list(pattern_dict.values())) / total
    prob = prob[prob > 0]
    
    # è®¡ç®—æ•£å¸ƒç†µ
    if len(prob) <= 1:
        return 0
    de_value = -np.sum(prob * np.log(prob))
    
    return de_value

def extract_IMSDE_features_optimized(signals, m=3, tau=1, c=6, max_scale=5):
    """ä¼˜åŒ–çš„IMSDEç‰¹å¾æå–"""
    print(f"\næå–IMSDEç‰¹å¾ (ä¼˜åŒ–ç‰ˆ):")
    print(f"  å‚æ•°: m={m}, tau={tau}, c={c}, æœ€å¤§å°ºåº¦: {max_scale}")
    
    n_samples = len(signals)
    n_features = max_scale
    features = np.zeros((n_samples, n_features))
    
    # è¿›åº¦è·Ÿè¸ª
    progress_interval = max(1, n_samples // 10)  # æ¯10%æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
    
    for i, signal in enumerate(signals):
        if i % progress_interval == 0:
            print(f"  è¿›åº¦: {i+1}/{n_samples} ({((i+1)/n_samples*100):.1f}%)")
        
        for scale in range(1, max_scale + 1):
            # å¤åˆç²—ç²’åŒ–
            if scale == 1:
                scaled_signal = signal
            else:
                length = len(signal) // scale
                scaled_signal = np.zeros(length)
                for j in range(length):
                    scaled_signal[j] = np.mean(signal[j*scale : (j+1)*scale])
            
            # è®¡ç®—æ•£å¸ƒç†µ
            de_value = optimized_multiscale_dispersion_entropy(scaled_signal, m, tau, c)
            features[i, scale-1] = de_value
    
    print(f"  ç‰¹å¾æå–å®Œæˆ!")
    return features

# ============================================================================
# ä¼˜åŒ–çš„PIDå‚æ•°æœç´¢
# ============================================================================

def PID_Optimize_Fast(src_signals, src_labels, tgt_signals, tgt_labels, search_space, n_iter=5):
    """å¿«é€ŸPIDå‚æ•°ä¼˜åŒ–"""
    print(f"\n{'='*50}")
    print(f"å¼€å§‹å¿«é€ŸPIDå‚æ•°ä¼˜åŒ–")
    print(f"{'='*50}")
    
    # é™åˆ¶å‚æ•°èŒƒå›´é¿å…è®¡ç®—çˆ†ç‚¸
    safe_search_space = {
        'm': [min(search_space['m']), min(max(search_space['m']), 6)],  # mæœ€å¤§6
        'c': [min(search_space['c']), min(max(search_space['c']), 8)]   # cæœ€å¤§8
    }
    
    print(f"å®‰å…¨å‚æ•°æœç´¢ç©ºé—´:")
    print(f"  m: {safe_search_space['m']}")
    print(f"  c: {safe_search_space['c']}")
    print(f"  è¿­ä»£æ¬¡æ•°: {n_iter}")
    
    best_accuracy = 0
    best_params = {}
    evolution_log = []
    
    for iteration in range(n_iter):
        # åœ¨å®‰å…¨èŒƒå›´å†…éšæœºé€‰æ‹©å‚æ•°
        m = np.random.randint(safe_search_space['m'][0], safe_search_space['m'][1] + 1)
        c = np.random.randint(safe_search_space['c'][0], safe_search_space['c'][1] + 1)
        
        print(f"\nè¿­ä»£ {iteration + 1}/{n_iter}:")
        print(f"  æµ‹è¯•å‚æ•°: m={m}, c={c}")
        
        try:
            # ä½¿ç”¨ä¼˜åŒ–çš„IMSDEç‰¹å¾æå–
            src_features = extract_IMSDE_features_optimized(src_signals, m=m, c=c, max_scale=3)  # å‡å°‘å°ºåº¦æ•°
            tgt_features = extract_IMSDE_features_optimized(tgt_signals, m=m, c=c, max_scale=3)
            
            # ELMåˆ†ç±»
            accuracy = ELM_classifier(src_features, src_labels, tgt_features, tgt_labels)
            
            evolution_log.append({
                'iteration': iteration + 1,
                'm': m,
                'c': c,
                'accuracy': accuracy
            })
            
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_params = {'m': m, 'c': c}
                print(f"  ğŸ¯ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {accuracy:.2f}%")
                
        except Exception as e:
            print(f"  é”™è¯¯: {str(e)}ï¼Œè·³è¿‡è¯¥å‚æ•°ç»„åˆ")
            continue
    
    print(f"\nPIDä¼˜åŒ–å®Œæˆ:")
    print(f"  æœ€ä½³å‚æ•°: m={best_params['m']}, c={best_params['c']}")
    print(f"  æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")
    
    # æ˜¾ç¤ºå‚æ•°æ¼”åŒ–
    print(f"\nå‚æ•°æ¼”åŒ–è¿‡ç¨‹:")
    for log in evolution_log:
        print(f"  è¿­ä»£{log['iteration']:2d}: m={log['m']}, c={log['c']}, å‡†ç¡®ç‡={log['accuracy']:.2f}%")
    
    return best_accuracy

# ============================================================================
# ä¸»å®éªŒå‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
# ============================================================================

def main_optimized():
    """ä¼˜åŒ–çš„ä¸»å®éªŒå‡½æ•°"""
    print("\n" + "="*60)
    print("å¼€å§‹CWRUè½´æ‰¿æ•…éšœè¯Šæ–­å®éªŒ (ä¼˜åŒ–ç‰ˆ)")
    print("="*60)
    
    # æ•°æ®é…ç½®ï¼ˆä½¿ç”¨ä½ çš„å®é™…æ–‡ä»¶è·¯å¾„ï¼‰
    æºåŸŸæ–‡ä»¶ = {
        "normal": "data/CWRU/cwru_raw/48k Drive End Bearing Fault Data/Ball/0007/B007_0.mat",
        "inner": "data/CWRU/cwru_raw/48k Drive End Bearing Fault Data/Ball/0007/B007_0.mat",
        "outer": "data/CWRU/cwru_raw/48k Drive End Bearing Fault Data/Ball/0007/B007_0.mat", 
        "ball": "data/CWRU/cwru_raw/48k Drive End Bearing Fault Data/Ball/0007/B007_0.mat"
    }
    
    ç›®æ ‡åŸŸæ–‡ä»¶ = {
        "normal": {"path": "data/CWRU/cwru_raw/48k Drive End Bearing Fault Data/Ball/0007/B007_3.mat", "use_first": 50},
        "inner": "data/CWRU/cwru_raw/48k Drive End Bearing Fault Data/Ball/0007/B007_3.mat",
        "outer": "data/CWRU/cwru_raw/48k Drive End Bearing Fault Data/Ball/0007/B007_3.mat",
        "ball": {"path": "data/CWRU/cwru_raw/48k Drive End Bearing Fault Data/Ball/0007/B007_3.mat", "start_pos": 50*2048}
    }
    
    # åŠ è½½æ•°æ®
    print("\nåŠ è½½æ•°æ®...")
    src_signals, src_labels = load_cwru_data(æºåŸŸæ–‡ä»¶, samples_per_class=50)
    tgt_signals, tgt_labels = load_cwru_data(ç›®æ ‡åŸŸæ–‡ä»¶, samples_per_class=50)
    
    # å¿«é€Ÿå®éªŒ
    print("\n" + "="*60)
    print("å¼€å§‹å¿«é€Ÿè·¨åŸŸè¿ç§»å­¦ä¹ å®éªŒ")
    print("="*60)
    
    # 1. MDEæ–¹æ³•ï¼ˆå¿«é€Ÿï¼‰
    print("\n>>> æ–¹æ³•1: å¤šå°ºåº¦æ•£å¸ƒç†µ (MDE)")
    acc_mde = cross_domain_test(
        extract_MDE_features, 
        src_signals, src_labels, 
        tgt_signals, tgt_labels, 
        params={"m": 3, "c": 6}
    )
    
    # 2. IMSDEæ–¹æ³•ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    print("\n>>> æ–¹æ³•2: æ”¹è¿›å¤šå°ºåº¦æ•£å¸ƒç†µ (IMSDE-ä¼˜åŒ–)")
    acc_imsde = cross_domain_test(
        extract_IMSDE_features_optimized, 
        src_signals, src_labels, 
        tgt_signals, tgt_labels, 
        params={"m": 3, "c": 6, "max_scale": 3}  # å‡å°‘å°ºåº¦æ•°
    )
    
    # 3. å¿«é€ŸPIDä¼˜åŒ–
    print("\n>>> æ–¹æ³•3: å¿«é€ŸPIDä¼˜åŒ–çš„IMSDE")
    acc_pid = PID_Optimize_Fast(
        src_signals, src_labels, 
        tgt_signals, tgt_labels, 
        search_space={"m": [2, 6], "c": [4, 8]},  # ç¼©å°æœç´¢èŒƒå›´
        n_iter=4  # å‡å°‘è¿­ä»£æ¬¡æ•°
    )
    
    # ç»“æœæ±‡æ€»
    print("\n" + "="*60)
    print("å®éªŒæœ€ç»ˆç»“æœæ±‡æ€»")
    print("="*60)
    
    results = {
        "MDE": acc_mde,
        "IMSDE": acc_imsde,
        "PID-IMSDE": acc_pid
    }
    
    print("\nå‡†ç¡®ç‡å¯¹æ¯”:")
    for method, accuracy in results.items():
        print(f"  {method:12s}: {accuracy:6.2f}%")
    
    best_method = max(results, key=results.get)
    best_accuracy = results[best_method]
    print(f"\nğŸ‰ æœ€ä½³æ–¹æ³•: {best_method}")
    print(f"ğŸ† æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")
    
    return results

# ============================================================================
# æ‰§è¡Œä¼˜åŒ–ç‰ˆæœ¬
# ============================================================================

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ä¼˜åŒ–ç‰ˆæœ¬ - è®¡ç®—æ—¶é—´å¤§å¹…å‡å°‘!")
    print("ğŸ’¡ ä¸»è¦ä¼˜åŒ–:")
    print("  - é™åˆ¶ m â‰¤ 6, c â‰¤ 8 é¿å…è®¡ç®—çˆ†ç‚¸")
    print("  - å‡å°‘æœ€å¤§å°ºåº¦ä»5åˆ°3")
    print("  - ä½¿ç”¨å­—å…¸ä»£æ›¿å¤§æ•°ç»„å­˜å‚¨æ¨¡å¼")
    print("  - å‡å°‘PIDè¿­ä»£æ¬¡æ•°")
    print("  - é¢„è®¡æ€»æ—¶é—´: 1-2å°æ—¶\n")
    
    try:
        final_results = main_optimized()
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")